# Research & Emerging AI Models (Cutting-Edge Foundation)

These are AI research models that directly address layout generation, semantic understanding, or scene synthesis. They are not packaged products yet but represent the kinds of models Qyntara AI could build on or adapt.

## 1. LLM + Layout Models

*   **OptiScene**: Focuses on spatial reasoning models that produce layouts aligned with design intent, combining large language models with layout optimization. (arXiv)

## 2. Scene Generation Frameworks

*   **SceneLCM**: Explores end-to-end scene generation using latent consistency models.
*   **RoomPilot**: Focuses on control using multimodal AI, with semantic parsing and layout generation. (arXiv)

## 3. Spatial Reasoning Research

*   **DirectLayout**: Generates 3D interior layouts directly from text descriptions while reasoning about spatial relationships. (arXiv)

## 4. Foundational AI Model Categories

For deeper customization or building our own system, we can leverage:

*   **Large Language Models (LLMs)**: GPT-class models for natural language to design intent conversion.
*   **3D Generative / Diffusion Models**: Models trained to produce 3D object placement or scene layouts.
*   **Computer Vision Models**: For detecting objects, proportions, and spatial boundaries in images or scans.
*   **Optimization Algorithms + AI Planners**: Custom modules that blend AI suggestions with geometry rules and ergonomic constraints.

This research demonstrates how academic work is progressing toward AI that understands geometry, semantics, and layout principlesâ€”exactly the kind needed for Qyntara's advanced semantic grouping and placement validation features.
